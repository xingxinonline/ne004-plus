#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include "layer_cnn_weights.h"

const uint8_t LAYER_NUM = 14;
const uint32_t MAX_BUFFER_LEN = 2688;
IOFeature ifeature;
IOFeature ofeature;
CNNBuffer cnnBuffer;

TINPUT layer_0 =
{
    .layer_name = "input",
    .layer_type = "input",
    .layer_output_type = "int8",
    .layer_input_shape = {59, 10, 1},
    .layer_output_shape = {59, 10, 1},
    .layer_output_scale = 0.3954058289527893
};

TCNN2D layer_1 =
{
    .layer_relu = 1,
    .layer_name = "conv1",
    .layer_type = "conv2d",
    .layer_groups = 1,
    .layer_input_type = "int8",
    .layer_output_type = "uint8",
    .ctx = {.size = 0},
    .conv_params = {
        .input_offset = 0,
        .output_offset = 0,
        .stride = {.h = 1, .w = 1},
        .padding = {.h = 1, .w = 1},
        .dilation = {.h = 1, .w = 1},
        .activation = {.min = 0, .max = 255}
    },
    .input_dims = {.n = 1, .h = 59, .w = 10, .c = 1},
    .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1},
    .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0},
    .output_dims = {.n = 1, .h = 59, .w = 10, .c = 16}
};

TCNN2D layer_2 = {.layer_relu = 1,   .layer_name = "conv2", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 2, .w = 1}, .padding = {.h = 1, .w = 1}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 59, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 30, .w = 10, .c = 16}};

TCNN2D layer_3 = {.layer_relu = 1,   .layer_name = "conv3", .layer_type = "conv2d",  .layer_groups = 1, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .conv_params = {.input_offset = 0, .output_offset = 0, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 30, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 1, .w = 1, .c = 16}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 30, .w = 10, .c = 16}};

TCNN2D layer_4 = {.layer_relu = 1,   .layer_name = "conv4", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 2, .w = 1}, .padding = {.h = 1, .w = 1}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 30, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 15, .w = 10, .c = 16}};

TCNN2D layer_5 = {.layer_relu = 1,   .layer_name = "conv5", .layer_type = "conv2d",  .layer_groups = 1, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .conv_params = {.input_offset = 0, .output_offset = 0, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 15, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 1, .w = 1, .c = 16}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 15, .w = 10, .c = 16}};

TCNN2D layer_6 = {.layer_relu = 1,   .layer_name = "conv6", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 1}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 15, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 13, .w = 10, .c = 16}};

TCNN2D layer_7 = {.layer_relu = 1,   .layer_name = "conv7", .layer_type = "conv2d",  .layer_groups = 1, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .conv_params = {.input_offset = 0, .output_offset = 0, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 13, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 1, .w = 1, .c = 16}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 13, .w = 10, .c = 16}};

TCNN2D layer_8 = {.layer_relu = 1,   .layer_name = "conv8", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 2, .w = 2}, .padding = {.h = 1, .w = 2}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 13, .w = 10, .c = 16}, .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 7, .w = 6, .c = 16}};

TCNN2D layer_9 = {.layer_relu = 1,   .layer_name = "conv9", .layer_type = "conv2d",  .layer_groups = 1, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .conv_params = {.input_offset = 0, .output_offset = 0, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 7, .w = 6, .c = 16}, .filter_dims = {.n = 16, .h = 1, .w = 1, .c = 16}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 7, .w = 6, .c = 16}};

TCNN2D layer_10 = {.layer_relu = 1,   .layer_name = "conv10", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 1, .w = 1}, .padding = {.h = 1, .w = 1}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 7, .w = 6, .c = 16}, .filter_dims = {.n = 16, .h = 3, .w = 3, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 7, .w = 6, .c = 16}};

TCNN2D layer_11 = {.layer_relu = 1,   .layer_name = "conv11", .layer_type = "conv2d",  .layer_groups = 1, .layer_input_type = "uint8", .layer_output_type = "uint8", .ctx = {.size = 0},   .conv_params = {.input_offset = 0, .output_offset = 0, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = 0, .max = 255}}, .input_dims = {.n = 1, .h = 7, .w = 6, .c = 16}, .filter_dims = {.n = 16, .h = 1, .w = 1, .c = 16}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 7, .w = 6, .c = 16}};

TCNN2D layer_12 = {.layer_relu = 0,   .layer_name = "avgpool_pool1_level1", .layer_type = "conv2d",  .layer_groups = 16, .layer_input_type = "uint8", .layer_output_type = "int8", .ctx = {.size = 0},   .dw_conv_params = {.input_offset = 0, .output_offset = 0, .ch_mult = 1, .stride = {.h = 1, .w = 1}, .padding = {.h = 0, .w = 0}, .dilation = {.h = 1, .w = 1}, .activation = {.min = -128, .max = 127}}, .input_dims = {.n = 1, .h = 7, .w = 6, .c = 16}, .filter_dims = {.n = 16, .h = 7, .w = 6, .c = 1}, .bias_dims = {.n = 0, .h = 0, .w = 0, .c = 0}, .output_dims = {.n = 1, .h = 1, .w = 1, .c = 16}};

TLINEAR layer_13 = {.layer_name = "fc1", .layer_type = "linear", .layer_input_type = "int8", .layer_output_type = "int8", .layer_input_shape = {1, 1, 16}, .layer_output_shape = {1, 1, 13}};

void layer_weight_init()
{
    ifeature.feature_type = 0;
    ifeature.feature_buffer = (char *)malloc(sizeof(char) * 9440);
    ofeature.feature_type = 0;
#ifndef RISCV
    ofeature.feature_buffer = (char *)malloc(sizeof(char) * 9440);
    cnnBuffer.cnn_buffer = (char *)malloc(sizeof(int16_t) * MAX_BUFFER_LEN);
#else
    ofeature.feature_buffer = (char *)0x60000100;
    cnnBuffer.cnn_buffer = (char *)0x60002900;;
#endif
    cnnBuffer.buffer_type = 0;
    static int32_t layer_1_bias[16] = {7458, 2806, -169, -490, 13858, 2304, 1352, 6985, 3541, 16035, 931, 444, 2724, 9935, 821, 2146};
    static int8_t layer_1_weight[144] = {115, 37, 50, -36, -21, 36, -91, -49, -17, 81, -65, -106, -8, -84, -92, -67, 8, 21, -128, 31, -44, -36, -36, -21, 117, -29, 21, -52, -111, -46, -43, 19, 22, 92, 95, 26, 100, 126, -10, 70, 3, 5, 119, 57, 10, -95, 114, 45, -11, 5, 20, 97, -108, -59, 5, -64, -13, -20, -2, 2, 11, 70, 8, -14, -67, -87, -30, 72, 51, -4, 80, 16, -65, -20, 32, 16, 17, 41, 43, 17, -10, 92, 34, 32, 35, 43, 23, 114, 50, 60, 92, -33, -44, -23, -29, 23, -63, 67, 24, -88, 26, -7, -12, 9, 5, 53, -21, 4, -103, -100, 43, -6, -8, 15, 95, 97, -54, -9, -73, 49, 20, -100, -84, 58, -95, -110, -96, -7, 18, 4, -19, 8, 97, 36, -27, -96, -63, -11, 17, 1, -18, 75, -14, 15};
    static int8_t layer_1_weight_shift[16] = {8, 8, 6, 6, 9, 7, 6, 8, 7, 9, 6, 6, 7, 9, 6, 7};
    layer_1.quant_params.shift = layer_1_weight_shift;
    layer_1.layer_bias = layer_1_bias;
    layer_1.layer_weight = layer_1_weight;
    layer_1.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_2_bias[16] = {3063, -1463, 5247, -17, 700, 6124, 7594, 6355, -6541, -668, 2539, 236, 443, 109, 1849, -2186};
    static int8_t layer_2_weight[144] = {-115, -42, 32, 94, 6, 55, -81, 66, 18, 125, -53, -13, -82, 93, 31, -25, -22, 43, -40, -27, -128, -21, -69, -45, 71, 54, 41, -37, 46, -38, 18, 75, 102, 43, 40, 26, -52, -41, -5, -49, -17, 10, 13, -94, -34, 33, -54, 49, -25, 41, 83, 108, -20, 24, -57, -51, 79, -24, -87, 8, -36, 22, 44, -60, 1, 12, -26, 5, 14, -100, -66, -14, 9, 27, 8, -3, 54, 10, 0, 6, 4, 42, 15, 28, -8, -30, -11, -66, 87, 1, 33, 19, -13, 29, -26, 40, 17, 68, 81, 58, 10, 62, -43, -78, -70, -115, -47, -71, -64, 23, 124, -86, 2, 12, -26, 4, 104, -118, -42, -18, -5, -57, -16, 2, 58, 3, -32, 3, -73, 64, 14, 28, 64, -14, -11, 3, 56, 2, 34, 57, 33, -78, -28, 20};
    static int8_t layer_2_weight_shift[16] = {7, 8, 9, 8, 6, 8, 7, 7, 7, 6, 7, 7, 7, 7, 8, 8};
    layer_2.quant_params.shift = layer_2_weight_shift;
    layer_2.layer_bias = layer_2_bias;
    layer_2.layer_weight = layer_2_weight;
    layer_2.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_3_bias[16] = {-132, 3277, 4957, 2166, 4700, 1632, 1128, 12431, 2404, 1157, 1923, 3900, -1147, -863, 14211, 346};
    static int8_t layer_3_weight[256] = {-34, -49, 54, 39, -24, -76, 102, 109, -20, -26, -64, 65, 32, 26, 72, 3, 5, -1, -9, -12, -15, -25, 20, -3, 7, -10, -4, 9, 26, -22, -64, 15, 24, -69, 14, 1, -2, 22, -6, -4, 12, 23, 6, 3, -12, 34, -15, 6, -38, -27, -21, 40, 52, 73, -40, 29, 39, -111, 72, 54, 45, -25, -25, -77, 16, -60, -9, -53, -11, -30, -24, 53, 28, -44, -27, -114, -53, -18, -10, -13, 35, -13, -41, 81, 17, -35, 24, -89, -48, 1, 31, 71, -86, -99, -1, -29, 23, -7, 31, -21, -14, -30, -15, 19, 69, -29, -6, -7, -38, -19, 21, -33, -25, 113, -120, 53, -18, 9, 11, 3, -95, -39, -6, 34, -10, -125, -3, 65, -10, -23, 22, -24, -92, -7, 68, 13, 42, -53, 66, -108, -4, 24, 11, -33, 45, 22, -52, -11, -92, -4, 75, 30, 1, -43, 58, 3, -6, -20, -52, -69, 32, -14, -53, 20, -5, -32, -24, -37, 45, -76, 23, 8, -29, -16, -18, -28, -47, 9, 33, -25, -17, -4, -1, -32, -5, -57, -40, 14, -19, 80, 20, -18, -49, -20, -26, 106, -51, 61, 52, -78, -7, -18, 127, -28, -2, -32, -46, 89, 66, 14, 20, -65, -117, -78, 62, -1, 4, -45, 32, 69, 2, -29, 20, -50, -67, -17, 16, 30, 25, -6, -12, -27, -31, -3, -23, 42, 0, 1, -30, -22, 28, 64, -13, 9, -29, 34, -36, 9, -50, -5, 41, 4, -42, -32, -35, -2};
    static int8_t layer_3_weight_shift[16] = {7, 7, 8, 8, 7, 7, 6, 9, 8, 6, 6, 8, 6, 8, 9, 6};
    layer_3.quant_params.shift = layer_3_weight_shift;
    layer_3.layer_bias = layer_3_bias;
    layer_3.layer_weight = layer_3_weight;
    layer_3.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_4_bias[16] = {-199, -6686, 1010, -2725, -34, -296, 5702, -3520, -1449, -1022, 1855, 3028, 9242, 861, 8719, 11752};
    static int8_t layer_4_weight[144] = {-83, 106, 27, 93, 94, -2, -90, 35, 74, 39, 48, 54, -1, 88, -41, 74, 28, 33, 0, -14, -62, 45, -65, 99, -10, 45, -34, -34, -48, -12, -19, -58, 3, 30, -4, 39, -31, -6, -41, 77, -39, 37, 86, -65, 37, -13, -27, -62, -23, 123, -2, 107, 100, 34, -77, 53, 106, 26, 104, 23, -65, 127, -56, 62, 46, 50, -8, 6, -39, 71, -93, 11, 41, 67, -60, -62, -60, -40, 7, -99, 13, 51, 67, 53, -28, -36, -77, 46, -16, 36, 88, -76, 84, -51, -78, -66, 2, 105, -34, 57, 19, 25, -54, 6, 54, 14, 60, -29, -73, 82, -17, 10, 29, 39, -21, 22, 20, 47, -16, -101, 59, 47, -43, -20, -15, -37, 0, -79, 22, 34, 84, 38, -16, -40, -67, -39, 22, 4, 23, -28, 54, -63, -60, -48};
    static int8_t layer_4_weight_shift[16] = {6, 6, 5, 6, 6, 6, 7, 5, 6, 7, 7, 5, 8, 5, 5, 8};
    layer_4.quant_params.shift = layer_4_weight_shift;
    layer_4.layer_bias = layer_4_bias;
    layer_4.layer_weight = layer_4_weight;
    layer_4.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_5_bias[16] = {6626, 7284, 6547, 4604, -6307, -4991, 14774, -3172, 5886, 23430, 21431, 2867, 16837, -7186, 1388, -1664};
    static int8_t layer_5_weight[256] = {3, -36, 94, -15, 28, 10, -17, -30, -14, 24, 23, 12, 16, -3, 9, 26, 6, -14, -38, -75, -22, -32, 35, 30, 15, -13, -13, 5, 19, 76, -23, 30, 6, -51, -36, 52, -27, 21, 24, -3, 11, 37, 31, 5, -18, -12, 91, -50, 64, 86, 45, -33, -2, -1, 12, 61, 63, 41, -49, 47, 64, 21, -19, -41, 52, -27, 27, -37, 6, 17, 26, 34, 36, -55, -46, -1, -25, 89, 107, -30, -19, 25, -14, 25, 66, -14, -38, -56, -20, -1, 20, 14, 17, -1, 44, 40, 1, 9, 10, -14, 7, -24, -88, -53, -18, 11, 60, 6, 51, 20, -26, 54, 10, 7, -21, 62, 30, 16, 8, -42, 14, 5, 78, 55, -8, 48, 20, 17, 32, -8, -15, 5, -25, 46, 38, 72, 0, 23, -16, -20, 31, -6, 10, -80, 14, -59, -54, -54, 15, 29, 8, -13, 71, -85, 10, 36, 22, 18, -71, -27, -10, 56, -66, 24, -52, 11, 11, -5, -63, -48, -55, -20, 44, -32, 14, 31, 40, -113, 52, -2, 0, 35, -48, 79, -50, 48, -3, -4, -42, -16, 2, -41, 28, -83, 7, 83, -16, 3, 14, 36, -27, -67, 3, 36, 50, -9, -110, -62, 4, -53, 73, 22, 36, -10, 20, 52, 39, 43, -14, -31, -28, 56, -35, -24, 92, -21, -28, 59, -28, -17, 69, 57, 81, 80, -59, -25, 28, 45, -35, -29, 39, 28, 30, 35, -10, 76, -14, 7, 3, -13, -32, -128, 67, 3, -21, -34};
    static int8_t layer_5_weight_shift[16] = {8, 7, 8, 8, 7, 6, 8, 7, 7, 8, 8, 7, 8, 6, 7, 6};
    layer_5.quant_params.shift = layer_5_weight_shift;
    layer_5.layer_bias = layer_5_bias;
    layer_5.layer_weight = layer_5_weight;
    layer_5.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_6_bias[16] = {-10669, 6607, 998, 4092, 9147, 5380, -22432, 6281, -401, 11347, -8326, -1857, 6087, 31475, -1062, 9351};
    static int8_t layer_6_weight[144] = {69, 63, -114, -100, 72, -54, 95, 43, -7, -45, 127, 74, -91, 46, -83, -95, 91, -87, 79, 44, -33, 44, 94, 39, -71, 10, -1, -18, 11, -96, 45, -83, 81, 20, 82, -10, 55, 10, 17, -36, -100, -19, 17, -49, 1, -85, 4, 10, 25, -50, 23, -37, 72, -86, 66, -24, 28, -75, 53, 36, -76, 57, -98, -58, -3, -60, -43, 20, -13, 24, 86, -18, -64, 21, 13, -11, -4, -86, 55, -50, 66, 5, 4, 17, 49, 20, 1, -27, 63, -31, -42, 18, -21, -126, 15, -7, -68, -65, 67, -7, 74, -64, 26, -48, -28, -31, 39, 22, -52, -11, -52, -40, -100, 93, -118, -73, -35, 7, 59, -80, 113, -9, -7, -36, -4, -96, 24, -39, -7, 13, -37, 63, 18, 26, 7, -6, 63, -12, -38, 22, -6, -100, 11, -36};
    static int8_t layer_6_weight_shift[16] = {6, 7, 6, 6, 7, 7, 7, 7, 7, 6, 6, 6, 6, 9, 7, 7};
    layer_6.quant_params.shift = layer_6_weight_shift;
    layer_6.layer_bias = layer_6_bias;
    layer_6.layer_weight = layer_6_weight;
    layer_6.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_7_bias[16] = {1798, -201, 8532, -388, 13740, -19774, 9608, -5398, -6295, 5379, -1959, 29964, 30751, -6072, 6462, 27377};
    static int8_t layer_7_weight[256] = {58, -26, 46, -128, -61, 16, -5, 44, 34, 29, 25, 77, 19, 36, 8, -29, 40, 104, -122, 56, 39, 27, -5, 65, -13, -54, -29, -34, 125, -102, -60, -81, -40, -44, 26, 6, -11, -18, -10, -29, -2, 19, -31, -69, 47, -35, 13, -24, -37, 75, 82, -97, 6, -46, 0, 116, 62, 102, -18, -13, -2, -100, 62, -42, -96, -19, -2, -31, -41, 13, 52, -18, -18, -30, -113, 4, 52, -13, -38, -13, -119, -6, 3, 44, 116, 24, 40, 106, -7, 16, -26, -20, 74, -17, 44, 81, 64, -29, 35, 38, 8, -113, 8, -27, 6, -6, 5, -55, 80, -29, 89, -8, -19, -1, -24, -11, -7, 3, 114, 10, 0, -59, 25, 18, 63, -18, 89, 3, -1, 18, -21, 43, 82, 20, 31, -12, 6, 36, 34, -8, -1, 24, -103, 6, -13, 44, -19, 13, 76, 81, 34, 40, -11, -95, 79, -54, -59, -7, -47, 44, 65, -37, -38, 23, 14, -30, -48, 1, -5, 29, 8, -37, 49, -45, 4, 14, -17, 45, 54, 37, -118, 41, -45, -29, 80, -40, -37, 21, -30, 38, -7, 37, -25, 0, -4, 20, 7, -49, -42, 48, -6, -32, 25, 8, 71, -38, -19, 15, 94, 56, -16, 3, -47, 28, 99, 13, 116, 42, 33, -17, -8, 1, -7, -22, 28, -62, -63, 72, -2, -35, -37, 15, -5, -41, -5, 16, 70, -24, 2, 113, -46, 35, -44, -40, -20, 14, -5, -41, -27, -113, -63, 34, 8, -11, -106, 5};
    static int8_t layer_7_weight_shift[16] = {7, 8, 7, 7, 8, 7, 8, 7, 8, 9, 8, 9, 9, 7, 7, 9};
    layer_7.quant_params.shift = layer_7_weight_shift;
    layer_7.layer_bias = layer_7_bias;
    layer_7.layer_weight = layer_7_weight;
    layer_7.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_8_bias[16] = {-138, -5980, -6624, 11606, 144, 7936, -4183, 3483, -4056, 5638, -29, -2562, 409, 11918, -10220, 7824};
    static int8_t layer_8_weight[144] = {29, 37, 3, -70, 73, 20, -32, 66, 125, -117, -24, 21, -50, -45, 80, -27, 106, 51, 71, 46, -13, -40, 52, 78, -65, -78, 38, 54, 17, 16, -5, -74, 5, 18, 24, 22, -29, -120, 1, 38, -27, -38, 127, 48, 99, -47, 14, -96, 87, 68, 51, -52, 65, -19, -7, 36, 51, -28, 5, -68, -119, -80, 66, 25, 123, 80, 85, 103, -3, 73, 77, -9, 7, -40, -100, 33, 4, 26, -25, 2, 10, 35, 33, 33, -10, 48, 5, -7, -24, -41, 24, 53, 73, -66, 57, -90, 43, 50, 48, -1, 46, -103, 44, -96, -50, 33, -110, -108, -65, -91, 17, 55, 65, 65, 46, 88, 9, 43, 45, -53, 66, 13, -118, -23, 34, 23, -24, 24, 17, 14, 16, 25, -14, 58, 32, -2, 13, 6, -111, 28, 50, -78, 36, -15};
    static int8_t layer_8_weight_shift[16] = {8, 7, 6, 8, 6, 8, 6, 7, 6, 6, 5, 6, 6, 8, 7, 6};
    layer_8.quant_params.shift = layer_8_weight_shift;
    layer_8.layer_bias = layer_8_bias;
    layer_8.layer_weight = layer_8_weight;
    layer_8.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_9_bias[16] = {11717, -3418, 10439, 3362, 9916, -143, 24858, 12733, -6469, -1463, 1002, -1411, 10549, 8483, 9046, 5215};
    static int8_t layer_9_weight[256] = {-120, 54, 40, -37, 50, 3, -18, 74, -19, 72, -78, -81, -76, -6, 96, -44, -18, -9, 13, 22, 10, -22, -27, -13, -32, -23, -3, 66, 70, -2, 33, 16, -60, 34, 31, 32, -72, -32, -15, 11, -19, -20, 127, 11, -97, 106, -32, -41, 1, -2, 1, 20, 21, 11, 42, -46, 21, 68, -19, -30, -4, -19, 39, -51, 24, 16, 61, 6, 20, -40, -18, -14, -29, -34, 90, 7, 60, -21, -31, -98, 55, -3, -31, 22, 26, 13, -47, -39, -26, 1, -13, 37, -24, -7, 84, 10, 48, 8, -58, -52, -82, 22, 44, 51, 69, 53, 90, 61, 23, -73, 83, 4, -49, 36, -20, 45, -79, 22, 32, 44, -11, 36, -9, 8, -12, 5, -29, -46, -126, 42, -42, 1, -77, -22, 5, 12, -15, 105, 48, 3, 109, -10, -6, 86, -87, 8, 99, 2, 15, 13, 22, -37, 62, -8, -14, -61, 27, 60, 47, -26, -21, -41, 67, 44, 42, -46, 45, -21, 27, -76, 64, 1, -24, 14, -2, -22, -46, 29, 64, 113, 82, 10, 1, 14, -37, -58, -38, -37, 47, 61, -41, -111, 2, -114, 36, 106, 27, -109, -41, -77, -27, 71, -39, -46, -25, 33, 8, -54, -13, 4, -4, 16, 10, -33, -19, 0, -76, 15, 32, 34, 13, 65, 36, 3, -24, -80, 35, 48, -86, -48, 77, -23, 15, -21, 38, 51, -5, -26, -34, -51, -20, 4, -1, -15, 1, 2, -46, 31, -33, -34, 30, 29, 74, 8, 5, 12};
    static int8_t layer_9_weight_shift[16] = {9, 8, 7, 8, 9, 8, 10, 9, 9, 7, 8, 9, 9, 9, 8, 9};
    layer_9.quant_params.shift = layer_9_weight_shift;
    layer_9.layer_bias = layer_9_bias;
    layer_9.layer_weight = layer_9_weight;
    layer_9.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_10_bias[16] = {-960, -1721, 3091, -2405, 3212, -1119, 103, 164, 1303, 3597, -1257, 470, -4066, 2590, 2935, -2392};
    static int8_t layer_10_weight[144] = {-48, 51, 115, 8, -42, -4, 74, 5, 50, 102, 33, 85, 123, -44, 111, 23, -12, 19, 19, -55, -116, 9, -74, -1, -9, -100, 41, -16, -37, 81, 121, 8, 21, -38, 3, 13, 22, -19, -49, 24, 5, 15, 6, -5, 39, -1, 62, 55, 89, 92, 1, 85, -28, 79, -45, 83, 39, 9, -21, 44, 9, -17, -53, -6, 0, -18, -41, 17, -60, -27, 16, 4, -40, 41, 60, -92, 34, -12, -22, 17, 15, -40, 12, 59, 21, 40, 0, 6, -4, -21, 55, 11, 59, 18, 6, 31, 24, 32, -40, 51, -22, 10, 54, -61, -128, -36, 61, -23, -105, -41, -18, 97, 19, -15, -45, 61, 43, 23, 7, -42, 6, 33, -98, -1, 39, -58, -97, 4, -10, 77, -15, -1, 46, 47, 36, -9, -17, -40, 55, -17, 45, 25, -49, -36};
    static int8_t layer_10_weight_shift[16] = {6, 7, 8, 7, 7, 7, 6, 6, 5, 9, 8, 6, 7, 6, 8, 6};
    layer_10.quant_params.shift = layer_10_weight_shift;
    layer_10.layer_bias = layer_10_bias;
    layer_10.layer_weight = layer_10_weight;
    layer_10.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_11_bias[16] = {-1543, 832, -4448, 1974, 544, -2858, -7934, -1470, -5803, -6521, -156, -2780, -4202, 535, 1092, 1604};
    static int8_t layer_11_weight[256] = {14, -25, 30, 61, 15, 2, 32, 24, -107, 18, -100, 30, -18, 14, 44, 35, -15, -4, -1, 5, -1, -9, -16, -22, -88, 6, 4, 22, -2, -4, 0, 30, 23, 14, -30, 65, -32, 55, 8, 39, -41, 10, 30, 2, -55, 61, 22, 58, 38, -34, 45, 12, -19, 8, -42, 33, -122, 3, -52, 3, -75, -44, -20, 25, -1, -82, 4, -11, -48, 3, -43, 1, 6, 25, 0, 14, 2, 55, -27, -22, 34, 9, -62, 53, 38, -39, -27, -54, 23, 29, -2, -43, -27, -106, 59, 32, 39, 28, 14, 46, 37, 38, 97, 63, 24, -19, -53, 55, 6, -12, -55, 56, -19, 56, 33, 36, 14, 26, -31, -1, 6, 60, -18, -38, 14, -32, -65, -7, 40, 15, -53, 11, 77, 10, 30, -33, 21, -106, -7, -38, 12, 31, -36, 68, 17, 48, 48, 68, 6, 38, -19, -50, 21, 0, 2, -23, -14, -25, 53, 70, -23, 29, -2, 30, 16, -36, 16, 9, -64, -4, -38, -46, 56, -79, 22, -8, 84, 43, -45, -34, 13, 49, -7, -36, -89, 4, 20, -128, 14, 8, 12, -20, -91, 50, -67, -21, 13, -28, 20, 23, -6, -15, 13, -60, 32, 43, 10, -4, -22, -37, -5, -1, -44, 20, -115, 4, 12, 56, -34, 1, 26, 63, 8, 57, -22, -45, 58, 32, 68, 0, 5, -26, -58, -37, 5, -36, -113, -52, 10, 29, 4, 4, 11, 21, -66, -51, 44, 1, -57, -15, -65, -30, 36, 4, -21, -27};
    static int8_t layer_11_weight_shift[16] = {5, 4, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 4, 6, 5, 4};
    layer_11.quant_params.shift = layer_11_weight_shift;
    layer_11.layer_bias = layer_11_bias;
    layer_11.layer_weight = layer_11_weight;
    layer_11.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_12_bias[16] = {-36064, -109104, -25905, -1887, -115596, -11122, -9888, -20557, -11355, -31224, -52672, -5317, -16263, -136416, -26166, -29927};
    static int8_t layer_12_weight[672] = {124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108, 124, 127, 73, 88, 69, 84, 70, 71, 119, 88, 117, 101, 88, 122, 73, 108};
    static int8_t layer_12_weight_shift[16] = {8, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 8, 7, 8};
    layer_12.quant_params.shift = layer_12_weight_shift;
    layer_12.layer_bias = layer_12_bias;
    layer_12.layer_weight = layer_12_weight;
    layer_12.ctx.buf = cnnBuffer.cnn_buffer;
    static int32_t layer_13_bias[13] = {-536, -846, -667, -999, -989, -1579, -1272, -1606, -422, -1279, -896, -664, -758};
    static int8_t layer_13_weight[208] = {-7, 64, -68, 23, 28, -65, -30, -47, -32, -76, -50, 13, -65, -29, 42, 57, 9, -123, -95, -40, -43, 103, -58, 108, -60, -39, 35, 27, 65, 50, 27, -29, 8, -66, -32, 21, -5, 77, 61, -29, 0, 6, -6, -9, -23, -23, 10, -12, -35, 25, 33, 18, 36, -11, 4, 20, 51, -24, 34, 98, -68, 31, 19, -23, -20, -70, -22, -7, -4, -31, 7, 1, -37, 76, -68, 78, -14, 17, -46, 39, -10, -41, 14, -2, 49, -39, -30, -50, 2, 59, 37, -28, 15, 18, 74, -3, 55, 79, 12, -24, 119, 14, -20, 9, -77, 65, 52, -68, -33, 111, -49, -43, -11, -9, 84, -22, 95, -50, 82, 58, -72, -82, -96, 24, 111, -47, 89, -37, -20, -19, 33, 9, 27, 28, -17, 17, 34, -5, -70, -26, 55, -20, -23, 39, -65, 51, -20, 3, -44, -25, 77, 46, 2, 37, -8, -25, -4, 65, 51, 52, 8, -27, 67, 24, -22, -47, 17, -9, 0, -53, 110, -12, -24, -1, -35, 27, 34, -3, -22, 127, -16, -32, -5, 8, 16, 9, -4, 7, 19, 25, 12, -14, 60, 72, -14, -18, -20, -8, 13, -41, 11, -8, 16, 37, 38, 47, -16, -10};
    static int8_t layer_13_weight_shift[13] = {9, 9, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8};
    layer_13.layer_weight_shift = layer_13_weight_shift;
    layer_13.layer_bias = layer_13_bias;
    layer_13.layer_weight = layer_13_weight;
}

void layer_weight_destroy()
{
    free(ifeature.feature_buffer);
#ifndef RISCV
    free(ofeature.feature_buffer);
    free(cnnBuffer.cnn_buffer);
#endif
}
